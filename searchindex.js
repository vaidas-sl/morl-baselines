Search.setIndex({"docnames": ["algos/algorithms", "algos/multi_policy", "algos/multi_policy/capql", "algos/multi_policy/envelope", "algos/multi_policy/gpi_pd", "algos/multi_policy/linear_support", "algos/multi_policy/mp_mo_q_learning", "algos/multi_policy/pareto_q_learning", "algos/multi_policy/pcn", "algos/multi_policy/pgmorl", "algos/performances", "algos/single_policy", "algos/single_policy/eupg", "algos/single_policy/moq_learning", "community/community", "features/buffers", "features/evaluations", "features/hpo", "features/misc", "features/networks", "features/pareto", "features/performance_indicators", "features/scalarization", "features/weights", "index", "quickstart/overview"], "filenames": ["algos/algorithms.md", "algos/multi_policy.md", "algos/multi_policy/capql.md", "algos/multi_policy/envelope.md", "algos/multi_policy/gpi_pd.md", "algos/multi_policy/linear_support.md", "algos/multi_policy/mp_mo_q_learning.md", "algos/multi_policy/pareto_q_learning.md", "algos/multi_policy/pcn.md", "algos/multi_policy/pgmorl.md", "algos/performances.md", "algos/single_policy.md", "algos/single_policy/eupg.md", "algos/single_policy/moq_learning.md", "community/community.md", "features/buffers.md", "features/evaluations.md", "features/hpo.md", "features/misc.md", "features/networks.md", "features/pareto.md", "features/performance_indicators.md", "features/scalarization.md", "features/weights.md", "index.md", "quickstart/overview.md"], "titles": ["Overview", "Multi-Policy Algorithms", "Concave-Augmented Pareto Q-Learning (CAPQL)", "Envelope Q-Learning", "GPI-Prioritized Dyna", "Linear Support", "MPMOQ Learning", "Pareto Q-Learning", "Pareto Conditioned Networks", "PGMORL", "Performance assessments", "Single-policy Algorithms", "EUPG", "MOQ-Learning", "Community", "Replay Buffers", "Evaluations", "Hyperparameter optimization", "Miscellaneous", "Neural Networks helpers", "Pareto utils", "Performance indicators", "Scalarization functions", "Weights helpers", "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.", "Overview"], "terms": {"morl": [0, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 17, 18, 21, 25], "baselin": [0, 2, 3, 4, 6, 7, 8, 9, 12, 13, 14, 17, 18, 25], "contain": [0, 15, 16, 17, 24, 25], "multipl": [0, 3, 9, 15, 16, 18], "implement": [0, 5, 9, 10, 14, 15, 24, 25], "multi": [0, 2, 3, 4, 6, 7, 9, 12, 13, 16, 17, 19, 21, 25], "object": [0, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 16, 17, 21], "reinforc": [0, 2, 3, 6, 7, 9, 10, 12, 13, 15, 17, 19], "learn": [0, 4, 8, 9, 10, 12, 14, 15, 17, 19], "algorithm": [0, 2, 3, 4, 5, 6, 7, 9, 12, 13, 14, 15, 17, 20, 21, 25], "The": [0, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 15, 17, 18, 19, 20, 24, 25], "follow": [0, 6, 10, 15, 17, 18, 19, 24, 25], "tabl": [0, 6, 10, 13], "list": [0, 2, 3, 4, 5, 6, 7, 8, 9, 12, 15, 16, 18, 19, 20, 21, 23], "ar": [0, 5, 9, 10, 14, 15, 17, 20, 21, 23, 24], "current": [0, 3, 5, 7, 9, 10, 14, 15, 16, 18, 19, 21], "name": [0, 2, 3, 4, 6, 7, 8, 9, 12, 13, 17], "singl": [0, 13, 24, 25], "polici": [0, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 16, 21, 24, 25], "esr": [0, 12, 15, 16, 24, 25], "ser": [0, 9, 13, 24, 25], "observ": [0, 2, 3, 8, 9, 12, 13, 15, 19], "space": [0, 9, 10, 23], "action": [0, 2, 3, 4, 6, 7, 8, 9, 12, 13, 15], "paper": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 17, 19, 21, 24], "gpi": [0, 2, 5, 6, 13], "l": [0, 4, 5, 6, 10, 21, 24], "pd": [0, 2, 4, 6, 13], "continu": [0, 2, 8, 9, 10], "discret": 0, "supplementari": [0, 9], "materi": [0, 9], "envelop": [0, 17], "q": [0, 6, 13, 14, 17], "capql": 0, "pgmorl": [0, 10, 21], "1": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 18, 19, 23], "pareto": [0, 3, 4, 6, 9, 10, 14, 16, 21, 24], "condit": [0, 2, 3, 12, 16], "network": [0, 2, 3, 4, 9, 12], "pcn": [0, 8, 14], "2": [0, 2, 4, 8, 9, 10, 15], "mo": [0, 6, 10, 13, 16, 24, 25], "mpmoqlearn": [0, 6, 13], "outer": [0, 6], "loop": [0, 6], "moql": 0, "optimist": [0, 5, 6], "linear": [0, 6, 12], "support": [0, 4, 6, 9, 10, 24], "ol": [0, 5, 6], "section": [0, 5, 9], "3": [0, 5, 7, 9, 10, 17, 24], "thesi": [0, 5], "expect": [0, 10, 12, 16, 21], "util": [0, 5, 10, 12, 16, 18, 19, 21, 23, 24], "gradient": [0, 2, 3, 4, 9, 12], "eupg": [0, 14], "warn": [0, 10], "some": [0, 9, 10, 21, 24], "have": [0, 9, 10, 14, 18, 20, 24], "limit": 0, "featur": [0, 14, 19], "i": [0, 3, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], "environ": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 16, 18, 24, 25], "assum": 0, "determinist": 0, "transit": [0, 4, 15], "class": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 19, 20], "morl_baselin": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 20, 21, 22, 23], "multi_polici": [2, 3, 4, 5, 6, 7, 8, 9, 25], "env": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 16, 17, 18], "learning_r": [2, 3, 4, 6, 8, 9, 12, 13], "float": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 21, 22], "0": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 17, 18, 19, 23], "0003": [2, 3, 4, 9], "gamma": [2, 3, 4, 6, 7, 8, 9, 12, 13], "99": [2, 3, 4, 12], "tau": [2, 3, 4, 19, 22], "005": 2, "buffer_s": [2, 3, 4, 12], "int": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 18, 19, 21, 22, 23], "1000000": [2, 3, 4], "net_arch": [2, 3, 4, 9, 12, 19], "256": [2, 3, 4, 8], "batch_siz": [2, 3, 4, 8, 15], "128": [2, 4], "num_q_net": 2, "alpha": [2, 3, 4, 12, 13, 23], "learning_start": [2, 3, 4, 13], "1000": [2, 4, 6, 7, 12, 13], "gradient_upd": [2, 3, 4], "project_nam": [2, 3, 4, 6, 7, 8, 9, 12, 13], "str": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 18, 21, 23], "experiment_nam": [2, 3, 4, 6, 7, 8, 9, 12, 13], "wandb_ent": [2, 3, 4, 6, 7, 8, 9, 12, 13], "none": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 19, 23], "log": [2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 16], "bool": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 19, 20, 21], "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 20, 21], "seed": [2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 16, 17, 23], "devic": [2, 3, 4, 8, 9, 12, 15], "auto": [2, 3, 4, 8, 9, 12], "convex": [2, 10, 20], "stationar": 2, "AND": 2, "optim": [2, 3, 4, 5, 6, 7, 8, 10, 21, 24], "haoy": 2, "lu": 2, "daniel": 2, "herman": 2, "yaoliang": 2, "yu": 2, "iclr": 2, "2023": [2, 4, 17, 24], "http": [2, 3, 4, 5, 8, 9, 10, 15, 20, 23, 24], "openreview": 2, "net": [2, 3, 9, 19, 25], "pdf": [2, 5, 8, 9], "id": [2, 9, 13, 15, 16, 17], "tjezisyesq6": 2, "code": [2, 8, 9, 15, 20, 24], "base": [2, 7, 9, 10, 12, 21], "github": [2, 8, 9, 15], "com": [2, 8, 9, 15, 20], "haoyelu": 2, "It": [2, 10, 16, 17, 19, 22, 23, 24], "extend": 2, "soft": [2, 3, 4], "actor": [2, 9], "critic": [2, 9], "rl": [2, 9, 21, 24], "weight": [2, 3, 4, 5, 6, 8, 10, 12, 13, 16, 18, 19, 21, 22, 24], "vector": [2, 3, 4, 5, 7, 9, 16, 19, 20, 21, 22, 23], "paramet": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23], "gym": [2, 4, 7, 8], "train": [2, 3, 4, 6, 7, 8, 9, 12, 13, 16, 17, 18], "option": [2, 3, 4, 5, 6, 7, 8, 12, 13, 16, 20], "rate": [2, 3, 4, 6, 8, 9, 12, 13, 19], "default": [2, 5, 7, 8, 9, 10, 15, 16, 17, 20, 21, 23], "3e": 2, "4": [2, 3, 9], "discount": [2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 16], "factor": [2, 3, 4, 6, 7, 8, 9, 12, 13], "updat": [2, 3, 4, 6, 8, 9, 12, 13, 15, 19], "coeffici": [2, 3, 4, 9, 19], "size": [2, 3, 4, 8, 9, 12, 15, 23], "replai": [2, 3, 4, 8, 12, 25], "buffer": [2, 3, 4, 8, 9, 12, 24, 25], "1e6": 2, "architectur": [2, 4, 19], "batch": [2, 3, 4, 8, 15, 20], "number": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 19, 23], "us": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 21, 23, 24, 25], "entropi": [2, 9], "regular": 2, "step": [2, 3, 4, 6, 7, 8, 9, 13, 16, 18], "take": [2, 3, 16], "befor": [2, 3, 4, 9, 13, 18], "start": [2, 3, 4, 9, 13, 15, 17], "100": [2, 3, 4, 6, 8, 9, 17], "per": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 16, 19], "project": [2, 3, 4, 6, 7, 8, 9, 12, 13, 14], "experi": [2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 17, 24], "wandb": [2, 3, 4, 7, 8, 9, 10, 12, 18, 24], "entiti": [2, 3, 4, 6, 7, 8, 9, 12, 13], "whether": [2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 16, 19, 20], "union": [2, 8], "th": [2, 8], "eval": [2, 3, 4, 6, 8, 9, 10, 12, 13], "ob": [2, 3, 4, 5, 6, 8, 9, 12, 13, 15], "ndarrai": [2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 16, 18, 19, 20, 21, 22, 23], "tensor": [2, 3, 4, 15, 19], "w": [2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 16], "torch_act": 2, "fals": [2, 3, 4, 5, 6, 9, 13, 15, 16, 17, 19, 20], "evalu": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 20], "given": [2, 3, 4, 6, 7, 8, 9, 12, 13, 15, 19], "get_config": [2, 3, 4, 6, 7, 8, 9, 12, 13], "get": [2, 5, 6, 7, 8, 14, 15], "configur": [2, 3, 4, 6, 7, 8, 9, 10, 12, 13], "agent": [2, 3, 4, 5, 8, 9, 10, 12, 13, 16, 18], "load": [2, 3, 4], "path": [2, 3, 4], "load_replay_buff": [2, 3, 4], "from": [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 21, 23, 24], "file": [2, 17, 25], "save": [2, 3, 4, 8, 18], "save_dir": [2, 3, 4], "filenam": [2, 3, 4, 8], "save_replay_buff": [2, 3, 4], "": [2, 3, 9, 10, 12, 15, 16, 23, 25], "total_timestep": [2, 3, 4, 6, 7, 8, 9, 12, 13, 17], "eval_env": [2, 3, 4, 6, 7, 8, 9, 12, 13], "ref_point": [2, 3, 4, 6, 7, 8, 9, 21], "known_pareto_front": [2, 3, 4, 6, 7, 8, 9], "num_eval_weights_for_front": [2, 3, 4, 6, 17], "num_eval_episodes_for_front": [2, 3, 4, 6], "5": [2, 3, 4, 6, 9, 13, 16], "eval_freq": [2, 3, 4, 6, 12, 13, 17], "reset_num_timestep": [2, 3, 4, 13, 17], "total": [2, 3, 6, 8], "timestep": [2, 3, 4, 6, 7, 12, 13, 16], "np": [2, 3, 4, 5, 8, 12, 13, 16, 18, 21], "refer": [2, 3, 4, 6, 7, 8, 9, 16, 17, 21, 22], "point": [2, 3, 4, 6, 7, 8, 9, 10, 16, 17, 20, 21, 22], "hypervolum": [2, 3, 4, 6, 7, 8, 10, 16, 17, 21], "calcul": [2, 4, 6, 8, 20], "front": [2, 3, 4, 6, 7, 8, 10, 16, 20, 21], "known": [2, 3, 4, 6, 7, 8, 16, 21], "episod": [2, 3, 4, 6, 7, 8, 12, 16, 18], "run": [2, 3, 4, 6, 9, 10, 12, 16, 18, 24], "when": [2, 3, 4, 5, 6, 9, 10, 13, 15, 18], "between": [2, 4, 10, 13, 21], "dure": [2, 7, 9], "an": [2, 3, 4, 5, 7, 9, 10, 14, 16, 17, 18, 19, 24], "iter": [2, 4, 5, 6, 9, 19], "reset": [2, 3, 4, 13, 18], "initial_epsilon": [3, 4, 6, 7, 13], "01": [3, 4, 15, 19], "final_epsilon": [3, 4, 6, 7, 13], "epsilon_decay_step": [3, 4, 6, 7, 13], "target_net_update_freq": [3, 4], "200": [3, 17], "max_grad_norm": [3, 4, 9], "num_sample_w": 3, "per_alpha": 3, "6": [3, 4, 9, 13], "initial_homotopy_lambda": 3, "final_homotopy_lambda": 3, "homotopy_decay_step": 3, "group": [3, 9], "lean": [3, 17], "emb": 3, "input": [3, 4, 19, 20], "main": [3, 9, 14, 15, 16], "chang": [3, 4, 9, 10, 20], "thi": [3, 8, 9, 10, 14, 15, 16, 18, 19, 20, 22, 24, 25], "compar": 3, "scalar": [3, 5, 6, 9, 10, 12, 13, 16], "cn": 3, "dqn": [3, 18, 19], "target": [3, 4, 9, 15, 19], "r": [3, 21], "yang": 3, "x": [3, 19], "sun": 3, "k": [3, 6, 7, 13], "narasimhan": 3, "A": [3, 6, 7, 8, 9, 10, 12, 13, 15, 17, 18, 20, 21], "gener": [3, 4, 5, 6, 10, 12, 13, 16, 18, 21, 23], "adapt": [3, 9, 22], "arxiv": [3, 4, 5, 17], "1908": 3, "08342": 3, "c": [3, 4, 10, 24], "nov": [3, 9, 10], "2019": 3, "access": 3, "sep": 3, "06": 3, "2021": 3, "onlin": 3, "avail": [3, 8, 9, 10, 15, 17, 24], "org": [3, 4, 5, 8, 23], "ab": [3, 4, 5], "initi": [3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 19, 20], "epsilon": [3, 4, 5, 6, 7, 13, 15, 18], "valu": [3, 4, 5, 6, 7, 9, 10, 13, 15, 16, 17, 18, 21, 22], "greedi": [3, 4, 13], "explor": 3, "final": [3, 4, 6, 7, 10, 13, 18], "decai": [3, 4, 6, 7, 13, 18], "over": [3, 6, 13, 18], "keep": [3, 9], "frequenc": [3, 4, 6, 12], "which": [3, 5, 9, 10, 15, 18, 19, 20, 24], "hidden": [3, 8], "layer": [3, 4, 9, 12, 19], "sampl": [3, 4, 8, 9, 15, 16, 23], "e": [3, 8, 9, 12, 15, 16, 17, 21, 24], "random": [3, 4, 6, 7, 9, 12, 13, 16, 23], "until": [3, 18], "maximum": [3, 4, 5, 6, 8, 9, 10, 15, 16, 21], "norm": [3, 4, 9, 19], "clip": [3, 8, 9], "If": [3, 5, 6, 7, 13, 14, 15, 16, 24], "appli": [3, 9, 15], "method": [3, 6, 7, 10, 13, 15, 19, 23], "priorit": [3, 6, 13], "homotopi": 3, "act": 3, "greedili": 3, "select": [3, 4, 6, 7, 9], "return": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 24], "integ": 3, "repres": [3, 19], "ddqn_target": 3, "doubl": 3, "envelope_target": 3, "sampled_w": 3, "comput": [3, 5, 7, 9, 10, 15, 16, 18, 19, 20, 21], "set": [3, 4, 5, 6, 7, 8, 10, 15, 16, 17, 20, 21, 24, 25], "give": [3, 12, 13, 15], "best": [3, 6, 9, 12, 13, 22], "arrai": [3, 6, 9, 12, 13, 15, 18, 20, 24], "dictionari": [3, 6, 7, 9, 12, 13, 15, 16], "dict": [3, 6, 7, 8, 9, 12, 13, 16], "config": [3, 6, 9, 12, 13, 17], "model": [3, 4, 8, 13], "specifi": [3, 15, 17], "too": 3, "max_act": [3, 4], "highest": [3, 5], "directori": [3, 17, 18], "total_episod": 3, "10000": [3, 4, 7, 17], "reset_learning_start": [3, 4], "verbos": [3, 5, 16], "ignor": 3, "randomli": 3, "everi": [3, 7], "done": [3, 15], "time": [3, 5, 8, 9, 13], "creat": [3, 13, 19], "print": [3, 16], "info": [3, 5, 16], "g": [3, 9, 12, 17, 21, 24], "gpi_pd": [4, 6, 13], "gpipd": 4, "type": [4, 8, 15, 19, 21], "num_net": 4, "20": [4, 8, 9], "use_gpi": [4, 6], "alpha_p": 4, "min_prior": [4, 13, 15, 19], "drop_rat": [4, 19], "layer_norm": [4, 19], "dynamics_normalize_input": 4, "dynamics_uncertainty_threshold": 4, "dynamics_train_freq": 4, "callabl": [4, 7, 21, 22], "function": [4, 5, 6, 7, 9, 10, 12, 13, 15, 16, 19, 20, 21, 24], "lambda": [4, 9, 15], "dynamics_rollout_len": 4, "dynamics_rollout_start": 4, "5000": 4, "dynamics_rollout_freq": 4, "250": 4, "dynamics_rollout_batch_s": 4, "25000": 4, "dynamics_buffer_s": 4, "100000": [4, 7, 12, 15], "dynamics_net_arch": 4, "dynamics_ensemble_s": 4, "dynamics_num_elit": 4, "real_ratio": 4, "torch": [4, 19], "effici": 4, "via": 4, "improv": [4, 5, 6, 13], "luca": [4, 14, 24], "n": [4, 8, 14, 15, 23, 24], "alegr": [4, 14, 24], "ana": [4, 24], "bazzan": [4, 24], "diederik": 4, "m": [4, 6, 8, 10, 13, 21], "roijer": [4, 5, 10, 12, 21], "ann": [4, 24], "now\u00e9": [4, 7, 8], "bruno": [4, 24], "da": [4, 24], "silva": [4, 24], "aama": 4, "2301": [4, 5], "07784": [4, 5], "minimum": [4, 5, 9, 13, 15, 19], "prioriti": [4, 5, 13, 15, 19], "dropout": [4, 19], "normal": [4, 9, 15, 19, 23], "dynam": 4, "uncertainti": 4, "threshold": [4, 9], "rollout": 4, "length": [4, 18, 19], "first": [4, 20], "ensembl": 4, "elit": 4, "ratio": 4, "real": 4, "gpi_act": 4, "return_policy_index": 4, "include_w": 4, "set_weight_support": 4, "weight_list": 4, "timesteps_per_it": 4, "weight_selection_algo": [4, 6], "train_iter": 4, "weight_support": 4, "change_w_every_episod": 4, "one": [4, 13, 16, 21, 23], "end": [4, 5, 15], "each": [4, 9, 10, 13, 15, 17, 19, 21, 22], "linear_support": 5, "linearsupport": 5, "num_object": 5, "corner": 5, "both": [5, 10, 24], "pub": 5, "add_solut": 5, "add": [5, 8, 9, 15, 20], "new": [5, 6, 9, 13, 14, 15], "indic": [5, 6, 15, 20], "remov": [5, 15, 20], "cc": [5, 10], "being": 5, "domin": [5, 7, 20, 22], "compute_corner_weight": 5, "see": [5, 9, 25], "definit": [5, 24], "19": 5, "typo": 5, "sign": 5, "should": [5, 9, 15, 16, 20], "queue": 5, "empti": 5, "get_corner_weight": 5, "top_k": 5, "get_weight_support": 5, "gpi_ls_prior": 5, "gpi_expanded_set": 5, "is_domin": 5, "check": [5, 15], "ani": [5, 21], "otherwis": [5, 6, 18], "max_scalarized_valu": 5, "max_value_lp": 5, "w_new": 5, "upper": 5, "bound": 5, "next_weight": 5, "algo": [5, 17], "gpi_ag": 5, "mopolici": 5, "rep_ev": 5, "next": [5, 9, 15], "either": [5, 23], "ols_prior": 5, "remove_obsolete_valu": 5, "longer": 5, "after": [5, 9, 19], "ad": [5, 15], "remove_obsolete_weight": 5, "new_valu": 5, "better": 5, "than": [5, 9], "previou": [5, 6, 15], "multi_policy_moqlearn": 6, "mp_mo_q_learn": 6, "weighted_sum": [6, 13, 22], "9": [6, 13], "epsilon_ol": 6, "use_gpi_polici": [6, 13], "transfer_q_t": 6, "dyna": [6, 13], "dyna_upd": [6, 13], "multipolici": 6, "moq": 6, "version": [6, 20], "mo_q_learn": [6, 13], "van": [6, 7, 13], "moffaert": [6, 7, 13], "drugan": [6, 13], "now": [6, 9, 12, 13, 24], "novel": [6, 13], "design": [6, 13, 24], "techniqu": [6, 13], "2013": [6, 13], "doi": [6, 10, 13, 17], "10": [6, 8, 9, 10, 13, 17], "1109": [6, 13], "adprl": [6, 13], "6615007": [6, 13], "reus": 6, "perform": [6, 9, 13, 24], "reproduc": [6, 8, 10, 16, 24], "delete_polici": 6, "delete_indx": 6, "delet": 6, "choos": [6, 13], "max_scalar_q_valu": 6, "state": [6, 7, 16, 21], "all": [6, 10, 14, 15, 16, 18, 20, 24, 25], "timesteps_per_iter": 6, "200000": 6, "metric": [6, 7, 8, 16, 21], "construct": 6, "pareto_q_learn": 7, "pql": 7, "8": 7, "tabular": 7, "reli": [7, 9, 10, 13, 21, 22], "prune": [7, 20, 24], "journal": 7, "machin": [7, 9, 10], "research": [7, 24], "vol": [7, 10], "15": 7, "pp": [7, 8, 9, 10], "3483": 7, "3512": 7, "2014": 7, "calc_non_domin": 7, "non": [7, 12, 20], "get_local_pc": 7, "collect": [7, 9, 19], "local": 7, "pc": 7, "get_q_set": 7, "pair": [7, 15], "score_hypervolum": 7, "score": 7, "upon": 7, "score_pareto_cardin": 7, "cardin": 7, "select_act": 7, "score_func": 7, "track_polici": 7, "vec": 7, "tol": [7, 18], "001": [7, 8, 12], "track": [7, 10, 24], "its": [7, 15, 20, 21], "array_lik": 7, "toler": [7, 18], "1e": [7, 8, 15], "log_everi": 7, "action_ev": 7, "eval_ref_point": 7, "same": [7, 15, 17, 18], "ref": [7, 17], "result": [7, 9, 10, 24], "scaling_factor": 8, "hidden_dim": 8, "64": [8, 9], "nois": 8, "model_class": 8, "basepcnmodel": 8, "reymond": [8, 14], "bargiacchi": 8, "2022": [8, 10], "mai": 8, "In": [8, 10], "proceed": [8, 9, 10, 24], "21st": 8, "intern": [8, 9, 10], "confer": [8, 9, 10, 24], "autonom": [8, 10], "multiag": 8, "system": [8, 10, 24], "1110": 8, "1118": 8, "www": 8, "ifaama": 8, "aamas2022": 8, "p1110": 8, "credit": 8, "refactor": [8, 9], "author": [8, 9, 24], "mathieu": [8, 14], "scale": [8, 9], "desir": 8, "horizon": 8, "32": [8, 9], "dimens": [8, 15, 19, 22], "standard": [8, 24], "deviat": 8, "case": [8, 13], "max_return": 8, "pcn_model": 8, "savedir": 8, "set_desired_return_and_horizon": 8, "desired_return": 8, "desired_horizon": 8, "num_er_episod": 8, "num_step_episod": 8, "num_model_upd": 8, "50": [8, 10, 12, 16, 18], "max_buffer_s": 8, "num_points_pf": 8, "fill": [8, 15, 16], "ha": [9, 16, 17], "been": [9, 18, 20, 24], "origin": [9, 10, 14], "provid": [9, 14, 15, 16, 20, 24], "post": 9, "process": [9, 16, 24], "phase": 9, "analysi": [9, 10], "stage": 9, "yet": 9, "ppo": 9, "look": 9, "variou": [9, 10, 14, 21, 24], "tradeoff": 9, "popul": 9, "along": [9, 10], "At": 9, "few": 9, "assign": 9, "further": 9, "histor": 9, "data": [9, 15], "gather": 9, "our": [9, 10, 14, 24], "essenti": 9, "cleanrl": [9, 24], "differ": [9, 17, 24], "sum": [9, 22], "note": 9, "might": 9, "possibl": [9, 10, 25], "enhanc": 9, "someth": 9, "els": 9, "single_polici": [9, 12, 13, 25], "mo_ppo": 9, "mopponet": 9, "syncvectorenv": 9, "steps_per_iter": 9, "2048": 9, "num_minibatch": 9, "update_epoch": 9, "995": 9, "anneal_lr": 9, "clip_coef": 9, "ent_coef": 9, "vf_coef": 9, "clip_vloss": 9, "norm_adv": 9, "target_kl": 9, "gae": 9, "gae_lambda": 9, "95": 9, "42": [9, 23], "rng": [9, 23], "modifi": 9, "clean": 9, "vwxyzjn": 9, "blob": 9, "master": 9, "ppo_continuous_act": 9, "py": [9, 10, 17], "minibatch": 9, "epoch": 9, "anneal": 9, "loss": [9, 10, 16, 19, 21], "advantag": 9, "kl": 9, "diverg": 9, "estim": 9, "change_weight": 9, "new_weight": 9, "numpi": [9, 13, 15, 16, 20, 21, 22, 24], "start_tim": [9, 13], "current_iter": 9, "max_iter": 9, "self": 9, "num_env": 9, "more": [9, 25], "detail": [9, 24, 25], "performancepredictor": 9, "neighborhood_threshold": 9, "sigma": 9, "03": 9, "a_bound_min": 9, "a_bound_max": 9, "500": 9, "f_scale": 9, "store": [9, 15], "delta": 9, "Then": 9, "regress": 9, "predictor": 9, "neighborhood": 9, "eval_before_pg": 9, "eval_after_pg": 9, "predict_next_evalu": 9, "weight_candid": 9, "policy_ev": 9, "tupl": [9, 15, 16], "part": 9, "determin": [9, 15], "whose": [9, 15], "candid": [9, 20], "env_id": 9, "pop_siz": 9, "warmup_iter": 9, "80": 9, "evolutionary_iter": 9, "num_weight_candid": 9, "7": 9, "num_performance_buff": 9, "performance_buffer_s": 9, "min_weight": 9, "max_weight": 9, "delta_weight": 9, "guid": [9, 10, 24], "j": [9, 10], "xu": [9, 10], "y": [9, 10], "tian": [9, 10], "p": [9, 10, 21], "ma": [9, 10], "d": [9, 10, 12, 17, 21], "ru": [9, 10], "sueda": [9, 10], "matusik": [9, 10], "robot": [9, 10], "control": [9, 10, 19], "37th": [9, 10, 24], "2020": [9, 10], "10607": [9, 10], "10616": [9, 10], "mlr": [9, 10], "press": [9, 10], "v119": [9, 10], "xu20h": [9, 10], "html": [9, 10, 23], "peopl": [9, 14], "csail": 9, "mit": 9, "edu": 9, "jiex": 9, "supp": 9, "make": [9, 16], "posit": [9, 15], "vectorizedenv": 9, "warmup": 9, "evolutionari": 9, "usual": [9, 19], "unit": [9, 12, 19], "term": [9, 10], "document": [10, 24, 25], "work": 10, "progress": 10, "To": 10, "ensur": 10, "correct": 10, "we": [10, 14, 15, 21, 24], "want": [10, 14], "test": [10, 24], "them": [10, 14], "For": [10, 17, 24], "sake": 10, "mainten": 10, "purpos": 10, "long": 10, "conduct": 10, "gymnasium": [10, 16, 24, 25], "henc": 10, "abl": 10, "were": 10, "present": 10, "keyword": 10, "scalarized_return": 10, "scalarized_discounted_return": 10, "propos": 10, "qualiti": [10, 21], "pf": [10, 21], "coverag": [10, 20], "converg": 10, "divers": 10, "hybrid": 10, "common": [10, 13, 15, 16, 18, 19, 20, 21, 22, 23, 25], "performance_ind": [10, 21], "sparsiti": [10, 16, 21], "averag": [10, 16, 19, 21], "distanc": [10, 15, 16, 21], "consecut": 10, "igd": [10, 16, 21], "sota": 10, "moo": [10, 21], "literatur": 10, "requir": [10, 21, 22], "can": [10, 12, 14, 24], "posteriori": 10, "That": [10, 23], "do": 10, "merg": 10, "found": [10, 24], "respect": 10, "moreov": 10, "assumpt": [10, 16], "user": 10, "These": [10, 15], "allow": 10, "idea": [10, 12, 14], "wherea": 10, "other": [10, 13, 15, 24], "eum": [10, 16, 21], "mul": [10, 16, 21], "problem": [10, 17, 21], "know": [10, 15, 21], "equal": [10, 23], "simplex": [10, 23], "also": [10, 14, 16, 24], "here": [10, 14, 24], "offici": 10, "sent": 10, "openrlbenchmark": [10, 24], "api": [10, 24], "queri": 10, "plot": 10, "format": [10, 24], "life": 10, "good": 10, "full": [10, 15], "flow": 10, "autom": 10, "cli": 10, "accordingli": 10, "locat": 10, "launch_experi": [10, 17], "below": [10, 15], "issu": [10, 14, 24], "predict": [10, 19], "hay": [10, 14], "et": [10, 18, 19], "al": [10, 18, 19], "practic": [10, 24], "plan": [10, 24], "36": 10, "apr": 10, "1007": 10, "s10458": 10, "022": 10, "09552": 10, "zintgraf": [10, 21], "t": [10, 21], "v": [10, 21], "kanter": [10, 21], "f": [10, 14, 17, 21], "oliehoek": [10, 21], "beau": [10, 21], "approach": [10, 21], "2015": [10, 18, 19, 21], "accru": [12, 16], "reward": [12, 16, 22, 24], "futur": 12, "steckelmach": [12, 14], "2018": 12, "nn": [12, 19], "cpu": 12, "cuda": 12, "accrued_reward": [12, 15], "moqlearn": 13, "model_bas": 13, "tabular_model": 13, "tabularmodel": 13, "0001": [13, 18], "parent": 13, "parent_rng": 13, "_gener": 13, "maintain": 13, "move": [13, 15], "wait": 13, "smooth": 13, "scalarized_q_valu": 13, "500000": 13, "max": 13, "recal": 13, "launch": [13, 17], "discord": 14, "server": 14, "where": 14, "you": [14, 24], "ask": 14, "question": [14, 20], "help": 14, "repositori": [14, 24], "join": 14, "florian": [14, 24], "felten": [14, 17, 24], "ffelten": 14, "lucasalegr": 14, "open": [14, 24], "alwai": [14, 22], "happi": 14, "receiv": 14, "bug": 14, "fix": 14, "discuss": [14, 17], "your": [14, 24], "u": 14, "pull": 14, "request": 14, "directli": 14, "asid": 14, "contributor": 14, "mani": 14, "who": 14, "wai": [14, 15], "would": 14, "like": 14, "thank": 14, "willem": 14, "r\u00f6pke": 14, "hi": 14, "wilrop": 14, "deni": 14, "conor": 14, "librari": [15, 24], "replaybuff": 15, "obs_shap": 15, "action_dim": 15, "rew_dim": 15, "max_siz": 15, "obs_dtyp": 15, "float32": 15, "action_dtyp": 15, "shape": [15, 19], "next_ob": 15, "get_all_data": 15, "max_sampl": 15, "replac": 15, "use_c": 15, "to_tensor": 15, "cer": 15, "convert": 15, "pytorch": [15, 24], "sample_ob": 15, "diverse_buff": 15, "diversememori": 15, "main_capac": 15, "sec_capac": 15, "trace_divers": 15, "crowding_divers": 15, "value_funct": 15, "integr": 15, "secondari": 15, "extract": [15, 19], "axelabel": 15, "dynmorl": 15, "capac": 15, "enforc": [15, 24], "trace": 15, "level": [15, 19], "crowd": 15, "error": 15, "power": 15, "rais": 15, "reduc": 15, "without": 15, "trace_id": 15, "pred_idx": 15, "tree_id": 15, "proport": 15, "treat": 15, "identifi": 15, "tree": 15, "relev": 15, "index": 15, "node": 15, "wa": 15, "add_sampl": 15, "write": 15, "add_tre": 15, "dupe": 15, "trg_i": 15, "src_i": 15, "copi": 15, "sourc": [15, 20], "extract_trac": 15, "those": 15, "get_data": 15, "include_indic": 15, "includ": 15, "get_error": 15, "idx": 15, "correspond": [15, 19], "get_sec_writ": 15, "secondary_trac": 15, "reserved_idx": 15, "find": 15, "free": 15, "spot": 15, "memori": [15, 20], "recurs": 15, "past": 15, "low": 15, "get_trace_valu": 15, "trace_tupl": 15, "main_mem_is_ful": 15, "becaus": 15, "circular": 15, "suffici": 15, "move_to_sec": 15, "span": 15, "remove_trac": 15, "sec_dist": 15, "prioritized_buff": 15, "prioritizedreplaybuff": 15, "05": 15, "update_prior": 15, "accrued_reward_buff": 15, "accruedrewardreplaybuff": 15, "action_shap": 15, "cleanup": 15, "whole": 15, "order": 15, "element": [15, 18, 20, 23], "relat": [16, 23], "eval_mo": 16, "dot": [16, 21, 22], "render": [16, 18], "linearreward": 16, "wrapper": 16, "eval_mo_reward_condit": 16, "log_all_multi_policy_metr": 16, "current_front": 16, "hv_ref_point": 16, "reward_dim": [16, 22], "global_step": 16, "n_sample_weight": 16, "ref_front": 16, "invert": [16, 21], "approxim": [16, 21], "global": 16, "log_episode_info": 16, "global_timestep": 16, "inform": [16, 24], "last": [16, 19], "automat": [16, 22, 24], "recordstatisticswrapp": 16, "statist": 16, "policy_evaluation_mo": 16, "rep": 16, "avg": 16, "seed_everyth": 16, "call": 16, "onli": [16, 21, 24], "onc": 16, "python": [16, 17, 20], "prefer": 16, "begin": [16, 18], "script": [16, 17], "effect": 16, "so": [16, 17, 18, 22], "care": 16, "earli": 17, "solut": [17, 20], "introduc": 17, "gareev": 17, "talbi": [17, 24], "danoi": [17, 24], "oct": 17, "25": 17, "48550": 17, "2310": 17, "16487": 17, "sweep": [17, 18], "benchmark": 17, "exampl": [17, 24, 25], "usag": 17, "hyperparameter_search": 17, "launch_sweep": 17, "minecart": 17, "v0": 17, "count": 17, "num": 17, "hyperparam": 17, "hp": 17, "search": 17, "try": [17, 18], "distribut": [17, 23], "yaml": 17, "11": 17, "12": 17, "linearly_decaying_valu": 18, "initial_valu": 18, "decay_period": 18, "warmup_step": 18, "final_valu": 18, "linearli": 18, "natur": [18, 19], "schedul": 18, "mnih": [18, 19], "taken": 18, "period": 18, "complet": 18, "far": [18, 22], "accord": 18, "make_gif": 18, "fullpath": 18, "fp": 18, "300": 18, "gif": 18, "reset_wandb_env": 18, "variabl": 18, "parallel": 18, "unique_tol": 18, "uniqu": 18, "within": 18, "naturecnn": 19, "observation_shap": 19, "features_dim": 19, "512": 19, "cnn": 19, "volodymyr": 19, "human": 19, "through": 19, "deep": 19, "518": 19, "7540": 19, "529": 19, "533": 19, "forward": 19, "get_grad_norm": 19, "param": 19, "how": 19, "grad": 19, "insid": 19, "clip_grad_norm_": 19, "huber": 19, "layer_init": 19, "orthogon": 19, "weight_gain": 19, "bias_const": 19, "gain": 19, "constant": 19, "bia": 19, "mlp": 19, "input_dim": 19, "output_dim": 19, "activation_fn": 19, "modul": 19, "activ": 19, "relu": 19, "sequenti": 19, "perceptron": 19, "fulli": 19, "connect": 19, "output": 19, "polyak_upd": 19, "target_param": 19, "polyak": 19, "small": 19, "paretoarch": 20, "convex_hul": 20, "archiv": 20, "ineffici": 20, "filter_convex_domin": 20, "fast": 20, "hull": 20, "leverag": 20, "quickhul": 20, "filter_pareto_domin": 20, "remove_dupl": 20, "duplic": 20, "get_non_domin": 20, "subset": 20, "stackoverflow": 20, "32791911": 20, "answer": 20, "wrong": 20, "import": 20, "made": [20, 21], "get_non_dominated_ind": 20, "boolean": 20, "get_non_pareto_dominated_ind": 20, "kept": 20, "form": 20, "mostli": 21, "pymoo": [21, 23], "axiomat": 21, "hv": 21, "customli": 21, "expected_util": 21, "weights_set": 21, "similar": 21, "But": 21, "need": 21, "assess": 21, "product": [21, 22], "_supportsarrai": 21, "dtype": 21, "_nestedsequ": 21, "complex": 21, "byte": 21, "known_front": 21, "current_estim": 21, "nearest": 21, "maximum_utility_loss": 21, "reference_set": 21, "basic": 21, "tchebicheff": 22, "seen": 22, "compon": 22, "sure": 22, "equally_spaced_weight": 23, "dim": 23, "riesz": 23, "energi": 23, "misc": 23, "reference_direct": 23, "extrema_weight": 23, "extrema": 23, "rest": 23, "random_weight": 23, "dist": 23, "dirichlet": 23, "gaussian": 23, "equival": 23, "uniformli": 23, "aim": 24, "reliabl": 24, "strictli": 24, "mdp": 24, "momdp": 24, "suggest": 24, "read": 24, "tutori": 24, "under": 24, "criteria": 24, "report": 24, "bias": 24, "dashboard": 24, "lint": 24, "pre": 24, "commit": 24, "hook": 24, "well": 24, "etc": [24, 25], "manner": 24, "hyperparamet": 24, "particip": 24, "popular": 24, "stabl": 24, "ai": 24, "43": 24, "experiment": 24, "protocol": 24, "websit": 24, "pleas": 24, "neurip": 24, "inproceed": 24, "felten_toolkit_2023": 24, "el": 24, "ghazali": 24, "gr": 24, "goir": 24, "castro": 24, "titl": 24, "toolkit": 24, "booktitl": 24, "neural": [24, 25], "year": 24, "As": 25, "much": 25, "repo": 25, "tri": 25, "rule": 25, "structur": 25, "recur": 25, "concept": 25}, "objects": {"morl_baselines.common.accrued_reward_buffer": [[15, 0, 1, "", "AccruedRewardReplayBuffer"]], "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer": [[15, 1, 1, "", "add"], [15, 1, 1, "", "cleanup"], [15, 1, 1, "", "get_all_data"], [15, 1, 1, "", "sample"]], "morl_baselines.common.buffer": [[15, 0, 1, "", "ReplayBuffer"]], "morl_baselines.common.buffer.ReplayBuffer": [[15, 1, 1, "", "add"], [15, 1, 1, "", "get_all_data"], [15, 1, 1, "", "sample"], [15, 1, 1, "", "sample_obs"]], "morl_baselines.common.diverse_buffer": [[15, 0, 1, "", "DiverseMemory"]], "morl_baselines.common.diverse_buffer.DiverseMemory": [[15, 1, 1, "", "add"], [15, 1, 1, "", "add_sample"], [15, 1, 1, "", "add_tree"], [15, 1, 1, "", "dupe"], [15, 1, 1, "", "extract_trace"], [15, 1, 1, "", "get"], [15, 1, 1, "", "get_data"], [15, 1, 1, "", "get_error"], [15, 1, 1, "", "get_sec_write"], [15, 1, 1, "", "get_trace_value"], [15, 1, 1, "", "main_mem_is_full"], [15, 1, 1, "", "move_to_sec"], [15, 1, 1, "", "remove_trace"], [15, 1, 1, "", "sample"], [15, 1, 1, "", "sec_distances"], [15, 1, 1, "", "update"]], "morl_baselines.common": [[16, 2, 0, "-", "evaluation"], [19, 2, 0, "-", "networks"], [20, 2, 0, "-", "pareto"], [21, 2, 0, "-", "performance_indicators"], [22, 2, 0, "-", "scalarization"], [18, 2, 0, "-", "utils"], [23, 2, 0, "-", "weights"]], "morl_baselines.common.evaluation": [[16, 3, 1, "", "eval_mo"], [16, 3, 1, "", "eval_mo_reward_conditioned"], [16, 3, 1, "", "log_all_multi_policy_metrics"], [16, 3, 1, "", "log_episode_info"], [16, 3, 1, "", "policy_evaluation_mo"], [16, 3, 1, "", "seed_everything"]], "morl_baselines.common.networks": [[19, 0, 1, "", "NatureCNN"], [19, 3, 1, "", "get_grad_norm"], [19, 3, 1, "", "huber"], [19, 3, 1, "", "layer_init"], [19, 3, 1, "", "mlp"], [19, 3, 1, "", "polyak_update"]], "morl_baselines.common.networks.NatureCNN": [[19, 1, 1, "", "forward"]], "morl_baselines.common.pareto": [[20, 0, 1, "", "ParetoArchive"], [20, 3, 1, "", "filter_convex_dominated"], [20, 3, 1, "", "filter_pareto_dominated"], [20, 3, 1, "", "get_non_dominated"], [20, 3, 1, "", "get_non_dominated_inds"], [20, 3, 1, "", "get_non_pareto_dominated_inds"]], "morl_baselines.common.pareto.ParetoArchive": [[20, 1, 1, "", "add"]], "morl_baselines.common.performance_indicators": [[21, 3, 1, "", "expected_utility"], [21, 3, 1, "", "hypervolume"], [21, 3, 1, "", "igd"], [21, 3, 1, "", "maximum_utility_loss"], [21, 3, 1, "", "sparsity"]], "morl_baselines.common.prioritized_buffer": [[15, 0, 1, "", "PrioritizedReplayBuffer"]], "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer": [[15, 1, 1, "", "add"], [15, 1, 1, "", "get_all_data"], [15, 1, 1, "", "sample"], [15, 1, 1, "", "sample_obs"], [15, 1, 1, "", "update_priorities"]], "morl_baselines.common.scalarization": [[22, 3, 1, "", "tchebicheff"], [22, 3, 1, "", "weighted_sum"]], "morl_baselines.common.utils": [[18, 3, 1, "", "linearly_decaying_value"], [18, 3, 1, "", "make_gif"], [18, 3, 1, "", "reset_wandb_env"], [18, 3, 1, "", "unique_tol"]], "morl_baselines.common.weights": [[23, 3, 1, "", "equally_spaced_weights"], [23, 3, 1, "", "extrema_weights"], [23, 3, 1, "", "random_weights"]], "morl_baselines.multi_policy.capql.capql": [[2, 0, 1, "", "CAPQL"]], "morl_baselines.multi_policy.capql.capql.CAPQL": [[2, 1, 1, "", "eval"], [2, 1, 1, "", "get_config"], [2, 1, 1, "", "load"], [2, 1, 1, "", "save"], [2, 1, 1, "", "train"], [2, 1, 1, "", "update"]], "morl_baselines.multi_policy.envelope.envelope": [[3, 0, 1, "", "Envelope"]], "morl_baselines.multi_policy.envelope.envelope.Envelope": [[3, 1, 1, "", "act"], [3, 1, 1, "", "ddqn_target"], [3, 1, 1, "", "envelope_target"], [3, 1, 1, "", "eval"], [3, 1, 1, "", "get_config"], [3, 1, 1, "", "load"], [3, 1, 1, "", "max_action"], [3, 1, 1, "", "save"], [3, 1, 1, "", "train"], [3, 1, 1, "", "update"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd": [[4, 0, 1, "", "GPIPD"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD": [[4, 1, 1, "", "eval"], [4, 1, 1, "", "get_config"], [4, 1, 1, "", "gpi_action"], [4, 1, 1, "", "load"], [4, 1, 1, "", "max_action"], [4, 1, 1, "", "save"], [4, 1, 1, "", "set_weight_support"], [4, 1, 1, "", "train"], [4, 1, 1, "", "train_iteration"], [4, 1, 1, "", "update"]], "morl_baselines.multi_policy.linear_support.linear_support": [[5, 0, 1, "", "LinearSupport"]], "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport": [[5, 1, 1, "", "add_solution"], [5, 1, 1, "", "compute_corner_weights"], [5, 1, 1, "", "ended"], [5, 1, 1, "", "get_corner_weights"], [5, 1, 1, "", "get_weight_support"], [5, 1, 1, "", "gpi_ls_priority"], [5, 1, 1, "", "is_dominated"], [5, 1, 1, "", "max_scalarized_value"], [5, 1, 1, "", "max_value_lp"], [5, 1, 1, "", "next_weight"], [5, 1, 1, "", "ols_priority"], [5, 1, 1, "", "remove_obsolete_values"], [5, 1, 1, "", "remove_obsolete_weights"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning": [[6, 0, 1, "", "MPMOQLearning"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning": [[6, 1, 1, "", "delete_policies"], [6, 1, 1, "", "eval"], [6, 1, 1, "", "get_config"], [6, 1, 1, "", "max_scalar_q_value"], [6, 1, 1, "", "train"]], "morl_baselines.multi_policy.pareto_q_learning.pql": [[7, 0, 1, "", "PQL"]], "morl_baselines.multi_policy.pareto_q_learning.pql.PQL": [[7, 1, 1, "", "calc_non_dominated"], [7, 1, 1, "", "get_config"], [7, 1, 1, "", "get_local_pcs"], [7, 1, 1, "", "get_q_set"], [7, 1, 1, "", "score_hypervolume"], [7, 1, 1, "", "score_pareto_cardinality"], [7, 1, 1, "", "select_action"], [7, 1, 1, "", "track_policy"], [7, 1, 1, "", "train"]], "morl_baselines.multi_policy.pcn.pcn": [[8, 0, 1, "", "PCN"]], "morl_baselines.multi_policy.pcn.pcn.PCN": [[8, 1, 1, "", "eval"], [8, 1, 1, "", "evaluate"], [8, 1, 1, "", "get_config"], [8, 1, 1, "", "save"], [8, 1, 1, "", "set_desired_return_and_horizon"], [8, 1, 1, "", "train"], [8, 1, 1, "", "update"]], "morl_baselines.multi_policy.pgmorl.pgmorl": [[9, 0, 1, "", "PGMORL"], [9, 0, 1, "", "PerformancePredictor"]], "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL": [[9, 1, 1, "", "get_config"], [9, 1, 1, "", "train"]], "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor": [[9, 1, 1, "", "add"], [9, 1, 1, "", "predict_next_evaluation"]], "morl_baselines.single_policy.esr.eupg": [[12, 0, 1, "", "EUPG"]], "morl_baselines.single_policy.esr.eupg.EUPG": [[12, 1, 1, "", "eval"], [12, 1, 1, "", "get_config"], [12, 1, 1, "", "train"], [12, 1, 1, "", "update"]], "morl_baselines.single_policy.ser.mo_ppo": [[9, 0, 1, "", "MOPPO"]], "morl_baselines.single_policy.ser.mo_ppo.MOPPO": [[9, 1, 1, "", "change_weights"], [9, 1, 1, "", "eval"], [9, 1, 1, "", "train"], [9, 1, 1, "", "update"]], "morl_baselines.single_policy.ser.mo_q_learning": [[13, 0, 1, "", "MOQLearning"]], "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning": [[13, 1, 1, "", "eval"], [13, 1, 1, "", "get_config"], [13, 1, 1, "", "scalarized_q_values"], [13, 1, 1, "", "train"], [13, 1, 1, "", "update"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:module", "3": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "module", "Python module"], "3": ["py", "function", "Python function"]}, "titleterms": {"overview": [0, 25], "multi": [1, 10, 15, 24], "polici": [1, 10, 11], "algorithm": [1, 10, 11, 24], "concav": 2, "augment": 2, "pareto": [2, 7, 8, 20], "q": [2, 3, 7], "learn": [2, 3, 6, 7, 13, 24], "capql": 2, "envelop": 3, "gpi": 4, "priorit": [4, 15], "dyna": 4, "linear": 5, "support": 5, "mpmoq": 6, "condit": 8, "network": [8, 19], "pgmorl": 9, "applic": 9, "limit": 9, "principl": 9, "moppo": 9, "weight": [9, 23], "gener": 9, "predict": 9, "model": 9, "perform": [10, 21], "assess": 10, "introduct": 10, "metric": 10, "singl": [10, 11], "storag": 10, "benchmark": [10, 24], "script": 10, "refer": 10, "eupg": 12, "moq": 13, "commun": 14, "maintain": 14, "contribut": 14, "acknowledg": 14, "replai": 15, "buffer": 15, "object": [15, 24], "divers": 15, "accru": 15, "reward": 15, "evalu": 16, "hyperparamet": 17, "optim": 17, "miscellan": 18, "neural": 19, "helper": [19, 23], "util": 20, "indic": 21, "scalar": 22, "function": 22, "morl": 24, "baselin": 24, "A": 24, "collect": 24, "reinforc": 24, "featur": 24, "cite": 24}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 60}, "alltitles": {"Overview": [[0, "overview"], [25, "overview"]], "Multi-Policy Algorithms": [[1, "multi-policy-algorithms"]], "Concave-Augmented Pareto Q-Learning (CAPQL)": [[2, "concave-augmented-pareto-q-learning-capql"]], "Envelope Q-Learning": [[3, "envelope-q-learning"]], "GPI-Prioritized Dyna": [[4, "gpi-prioritized-dyna"]], "Linear Support": [[5, "linear-support"]], "MPMOQ Learning": [[6, "mpmoq-learning"]], "Pareto Q-Learning": [[7, "pareto-q-learning"]], "Pareto Conditioned Networks": [[8, "pareto-conditioned-networks"]], "PGMORL": [[9, "pgmorl"], [9, "id1"]], "Applicability and limitations": [[9, "applicability-and-limitations"]], "Principle": [[9, "principle"]], "MOPPO": [[9, "moppo"]], "Weight generator - prediction model": [[9, "weight-generator-prediction-model"]], "Performance assessments": [[10, "performance-assessments"]], "Introduction": [[10, "introduction"]], "Metrics": [[10, "metrics"]], "Single-policy algorithms": [[10, "single-policy-algorithms"]], "Multi-policy algorithms": [[10, "multi-policy-algorithms"]], "Storage": [[10, "storage"]], "Benchmarking script": [[10, "benchmarking-script"]], "Algorithms": [[10, "algorithms"]], "References": [[10, "references"]], "Single-policy Algorithms": [[11, "single-policy-algorithms"]], "EUPG": [[12, "eupg"]], "MOQ-Learning": [[13, "moq-learning"]], "Community": [[14, "community"]], "Maintainers": [[14, "maintainers"]], "Contributing": [[14, "contributing"]], "Acknowledgements": [[14, "acknowledgements"]], "Replay Buffers": [[15, "replay-buffers"]], "Multi-Objective Replay Buffer": [[15, "multi-objective-replay-buffer"]], "Diverse Replay Buffer": [[15, "diverse-replay-buffer"]], "Prioritized Replay Buffer": [[15, "prioritized-replay-buffer"]], "Accrued Reward Replay Buffer": [[15, "accrued-reward-replay-buffer"]], "Evaluations": [[16, "module-morl_baselines.common.evaluation"]], "Hyperparameter optimization": [[17, "hyperparameter-optimization"]], "Miscellaneous": [[18, "module-morl_baselines.common.utils"]], "Neural Networks helpers": [[19, "module-morl_baselines.common.networks"]], "Pareto utils": [[20, "module-morl_baselines.common.pareto"]], "Performance indicators": [[21, "module-morl_baselines.common.performance_indicators"]], "Scalarization functions": [[22, "module-morl_baselines.common.scalarization"]], "Weights helpers": [[23, "module-morl_baselines.common.weights"]], "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.": [[24, "morl-baselines-a-collection-of-multi-objective-reinforcement-learning-algorithms"]], "Features of MORL-Baselines": [[24, "features-of-morl-baselines"]], "Benchmarks": [[24, "benchmarks"]], "Citing MORL-Baselines": [[24, "citing-morl-baselines"]]}, "indexentries": {"capql (class in morl_baselines.multi_policy.capql.capql)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL"]], "eval() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.eval"]], "get_config() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.get_config"]], "load() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.load"]], "save() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.save"]], "train() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.train"]], "update() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.update"]], "envelope (class in morl_baselines.multi_policy.envelope.envelope)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope"]], "act() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.act"]], "ddqn_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.ddqn_target"]], "envelope_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.envelope_target"]], "eval() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.eval"]], "get_config() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.get_config"]], "load() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.load"]], "max_action() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.max_action"]], "save() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.save"]], "train() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.train"]], "update() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.update"]], "gpipd (class in morl_baselines.multi_policy.gpi_pd.gpi_pd)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD"]], "eval() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.eval"]], "get_config() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.get_config"]], "gpi_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.gpi_action"]], "load() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.load"]], "max_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.max_action"]], "save() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.save"]], "set_weight_support() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.set_weight_support"]], "train() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train"]], "train_iteration() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train_iteration"]], "update() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.update"]], "linearsupport (class in morl_baselines.multi_policy.linear_support.linear_support)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport"]], "add_solution() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.add_solution"]], "compute_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.compute_corner_weights"]], "ended() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ended"]], "get_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_corner_weights"]], "get_weight_support() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_weight_support"]], "gpi_ls_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.gpi_ls_priority"]], "is_dominated() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.is_dominated"]], "max_scalarized_value() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_scalarized_value"]], "max_value_lp() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_value_lp"]], "next_weight() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.next_weight"]], "ols_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ols_priority"]], "remove_obsolete_values() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_values"]], "remove_obsolete_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_weights"]], "mpmoqlearning (class in morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning)": [[6, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning"]], "delete_policies() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[6, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.delete_policies"]], "eval() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[6, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.eval"]], "get_config() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[6, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.get_config"]], "max_scalar_q_value() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[6, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.max_scalar_q_value"]], "train() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[6, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.train"]], "pql (class in morl_baselines.multi_policy.pareto_q_learning.pql)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL"]], "calc_non_dominated() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.calc_non_dominated"]], "get_config() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_config"]], "get_local_pcs() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_local_pcs"]], "get_q_set() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_q_set"]], "score_hypervolume() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_hypervolume"]], "score_pareto_cardinality() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_pareto_cardinality"]], "select_action() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.select_action"]], "track_policy() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.track_policy"]], "train() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[7, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.train"]], "pcn (class in morl_baselines.multi_policy.pcn.pcn)": [[8, "morl_baselines.multi_policy.pcn.pcn.PCN"]], "eval() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[8, "morl_baselines.multi_policy.pcn.pcn.PCN.eval"]], "evaluate() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[8, "morl_baselines.multi_policy.pcn.pcn.PCN.evaluate"]], "get_config() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[8, "morl_baselines.multi_policy.pcn.pcn.PCN.get_config"]], "save() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[8, "morl_baselines.multi_policy.pcn.pcn.PCN.save"]], "set_desired_return_and_horizon() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[8, "morl_baselines.multi_policy.pcn.pcn.PCN.set_desired_return_and_horizon"]], "train() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[8, "morl_baselines.multi_policy.pcn.pcn.PCN.train"]], "update() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[8, "morl_baselines.multi_policy.pcn.pcn.PCN.update"]], "moppo (class in morl_baselines.single_policy.ser.mo_ppo)": [[9, "morl_baselines.single_policy.ser.mo_ppo.MOPPO"]], "pgmorl (class in morl_baselines.multi_policy.pgmorl.pgmorl)": [[9, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL"]], "performancepredictor (class in morl_baselines.multi_policy.pgmorl.pgmorl)": [[9, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor"]], "add() (morl_baselines.multi_policy.pgmorl.pgmorl.performancepredictor method)": [[9, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor.add"]], "change_weights() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[9, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.change_weights"]], "eval() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[9, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.eval"]], "get_config() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[9, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.get_config"]], "predict_next_evaluation() (morl_baselines.multi_policy.pgmorl.pgmorl.performancepredictor method)": [[9, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor.predict_next_evaluation"]], "train() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[9, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.train"]], "train() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[9, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.train"]], "update() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[9, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.update"]], "eupg (class in morl_baselines.single_policy.esr.eupg)": [[12, "morl_baselines.single_policy.esr.eupg.EUPG"]], "eval() (morl_baselines.single_policy.esr.eupg.eupg method)": [[12, "morl_baselines.single_policy.esr.eupg.EUPG.eval"]], "get_config() (morl_baselines.single_policy.esr.eupg.eupg method)": [[12, "morl_baselines.single_policy.esr.eupg.EUPG.get_config"]], "train() (morl_baselines.single_policy.esr.eupg.eupg method)": [[12, "morl_baselines.single_policy.esr.eupg.EUPG.train"]], "update() (morl_baselines.single_policy.esr.eupg.eupg method)": [[12, "morl_baselines.single_policy.esr.eupg.EUPG.update"]], "moqlearning (class in morl_baselines.single_policy.ser.mo_q_learning)": [[13, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning"]], "eval() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[13, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.eval"]], "get_config() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[13, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.get_config"]], "scalarized_q_values() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[13, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.scalarized_q_values"]], "train() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[13, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.train"]], "update() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[13, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.update"]], "accruedrewardreplaybuffer (class in morl_baselines.common.accrued_reward_buffer)": [[15, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer"]], "diversememory (class in morl_baselines.common.diverse_buffer)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory"]], "prioritizedreplaybuffer (class in morl_baselines.common.prioritized_buffer)": [[15, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer"]], "replaybuffer (class in morl_baselines.common.buffer)": [[15, "morl_baselines.common.buffer.ReplayBuffer"]], "add() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[15, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.add"]], "add() (morl_baselines.common.buffer.replaybuffer method)": [[15, "morl_baselines.common.buffer.ReplayBuffer.add"]], "add() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.add"]], "add() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[15, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.add"]], "add_sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.add_sample"]], "add_tree() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.add_tree"]], "cleanup() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[15, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.cleanup"]], "dupe() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.dupe"]], "extract_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.extract_trace"]], "get() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.get"]], "get_all_data() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[15, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.buffer.replaybuffer method)": [[15, "morl_baselines.common.buffer.ReplayBuffer.get_all_data"]], "get_all_data() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[15, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.get_all_data"]], "get_data() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.get_data"]], "get_error() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.get_error"]], "get_sec_write() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.get_sec_write"]], "get_trace_value() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.get_trace_value"]], "main_mem_is_full() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.main_mem_is_full"]], "move_to_sec() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.move_to_sec"]], "remove_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.remove_trace"]], "sample() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[15, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.sample"]], "sample() (morl_baselines.common.buffer.replaybuffer method)": [[15, "morl_baselines.common.buffer.ReplayBuffer.sample"]], "sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.sample"]], "sample() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[15, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample"]], "sample_obs() (morl_baselines.common.buffer.replaybuffer method)": [[15, "morl_baselines.common.buffer.ReplayBuffer.sample_obs"]], "sample_obs() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[15, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample_obs"]], "sec_distances() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.sec_distances"]], "update() (morl_baselines.common.diverse_buffer.diversememory method)": [[15, "morl_baselines.common.diverse_buffer.DiverseMemory.update"]], "update_priorities() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[15, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.update_priorities"]], "eval_mo() (in module morl_baselines.common.evaluation)": [[16, "morl_baselines.common.evaluation.eval_mo"]], "eval_mo_reward_conditioned() (in module morl_baselines.common.evaluation)": [[16, "morl_baselines.common.evaluation.eval_mo_reward_conditioned"]], "log_all_multi_policy_metrics() (in module morl_baselines.common.evaluation)": [[16, "morl_baselines.common.evaluation.log_all_multi_policy_metrics"]], "log_episode_info() (in module morl_baselines.common.evaluation)": [[16, "morl_baselines.common.evaluation.log_episode_info"]], "module": [[16, "module-morl_baselines.common.evaluation"], [18, "module-morl_baselines.common.utils"], [19, "module-morl_baselines.common.networks"], [20, "module-morl_baselines.common.pareto"], [21, "module-morl_baselines.common.performance_indicators"], [22, "module-morl_baselines.common.scalarization"], [23, "module-morl_baselines.common.weights"]], "morl_baselines.common.evaluation": [[16, "module-morl_baselines.common.evaluation"]], "policy_evaluation_mo() (in module morl_baselines.common.evaluation)": [[16, "morl_baselines.common.evaluation.policy_evaluation_mo"]], "seed_everything() (in module morl_baselines.common.evaluation)": [[16, "morl_baselines.common.evaluation.seed_everything"]], "linearly_decaying_value() (in module morl_baselines.common.utils)": [[18, "morl_baselines.common.utils.linearly_decaying_value"]], "make_gif() (in module morl_baselines.common.utils)": [[18, "morl_baselines.common.utils.make_gif"]], "morl_baselines.common.utils": [[18, "module-morl_baselines.common.utils"]], "reset_wandb_env() (in module morl_baselines.common.utils)": [[18, "morl_baselines.common.utils.reset_wandb_env"]], "unique_tol() (in module morl_baselines.common.utils)": [[18, "morl_baselines.common.utils.unique_tol"]], "naturecnn (class in morl_baselines.common.networks)": [[19, "morl_baselines.common.networks.NatureCNN"]], "forward() (morl_baselines.common.networks.naturecnn method)": [[19, "morl_baselines.common.networks.NatureCNN.forward"]], "get_grad_norm() (in module morl_baselines.common.networks)": [[19, "morl_baselines.common.networks.get_grad_norm"]], "huber() (in module morl_baselines.common.networks)": [[19, "morl_baselines.common.networks.huber"]], "layer_init() (in module morl_baselines.common.networks)": [[19, "morl_baselines.common.networks.layer_init"]], "mlp() (in module morl_baselines.common.networks)": [[19, "morl_baselines.common.networks.mlp"]], "morl_baselines.common.networks": [[19, "module-morl_baselines.common.networks"]], "polyak_update() (in module morl_baselines.common.networks)": [[19, "morl_baselines.common.networks.polyak_update"]], "paretoarchive (class in morl_baselines.common.pareto)": [[20, "morl_baselines.common.pareto.ParetoArchive"]], "add() (morl_baselines.common.pareto.paretoarchive method)": [[20, "morl_baselines.common.pareto.ParetoArchive.add"]], "filter_convex_dominated() (in module morl_baselines.common.pareto)": [[20, "morl_baselines.common.pareto.filter_convex_dominated"]], "filter_pareto_dominated() (in module morl_baselines.common.pareto)": [[20, "morl_baselines.common.pareto.filter_pareto_dominated"]], "get_non_dominated() (in module morl_baselines.common.pareto)": [[20, "morl_baselines.common.pareto.get_non_dominated"]], "get_non_dominated_inds() (in module morl_baselines.common.pareto)": [[20, "morl_baselines.common.pareto.get_non_dominated_inds"]], "get_non_pareto_dominated_inds() (in module morl_baselines.common.pareto)": [[20, "morl_baselines.common.pareto.get_non_pareto_dominated_inds"]], "morl_baselines.common.pareto": [[20, "module-morl_baselines.common.pareto"]], "expected_utility() (in module morl_baselines.common.performance_indicators)": [[21, "morl_baselines.common.performance_indicators.expected_utility"]], "hypervolume() (in module morl_baselines.common.performance_indicators)": [[21, "morl_baselines.common.performance_indicators.hypervolume"]], "igd() (in module morl_baselines.common.performance_indicators)": [[21, "morl_baselines.common.performance_indicators.igd"]], "maximum_utility_loss() (in module morl_baselines.common.performance_indicators)": [[21, "morl_baselines.common.performance_indicators.maximum_utility_loss"]], "morl_baselines.common.performance_indicators": [[21, "module-morl_baselines.common.performance_indicators"]], "sparsity() (in module morl_baselines.common.performance_indicators)": [[21, "morl_baselines.common.performance_indicators.sparsity"]], "morl_baselines.common.scalarization": [[22, "module-morl_baselines.common.scalarization"]], "tchebicheff() (in module morl_baselines.common.scalarization)": [[22, "morl_baselines.common.scalarization.tchebicheff"]], "weighted_sum() (in module morl_baselines.common.scalarization)": [[22, "morl_baselines.common.scalarization.weighted_sum"]], "equally_spaced_weights() (in module morl_baselines.common.weights)": [[23, "morl_baselines.common.weights.equally_spaced_weights"]], "extrema_weights() (in module morl_baselines.common.weights)": [[23, "morl_baselines.common.weights.extrema_weights"]], "morl_baselines.common.weights": [[23, "module-morl_baselines.common.weights"]], "random_weights() (in module morl_baselines.common.weights)": [[23, "morl_baselines.common.weights.random_weights"]]}})